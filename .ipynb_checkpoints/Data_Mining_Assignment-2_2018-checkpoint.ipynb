{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "from datetime import *\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas_ml as pdml\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, use Weka to load the arff input file and save as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Assignment2_Agency.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: Create a balanced dataset so that the number of instances of classes T,P,X,V,S and \"Others\" are close to equal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Combine minority classes to \"Others\", whose total are smaller than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by target classes\n",
    "groupClass = data.groupby(['Issuing Agency'])['Issuing Agency'].count()\n",
    "# Filter the records whose totals are less than 100\n",
    "minority_classes = list(groupClass[groupClass<100].index)\n",
    "# Combine minority classes to 'Others'\n",
    "data['Issuing Agency'] = data['Issuing Agency'].replace(minority_classes, 'Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Convert nominal data to numeric data.   \n",
    "I collect the columns' titles named as \"numericFields\", which data is numeric. Then get the nominal columns named as \"nominalFields\" based on numericFields and convert the nominal data to numeric data by using LabelEncoder library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericFields = ['Violation Code', 'Vehicle Expiration Date', 'Violation Location', 'Issuer Code', \n",
    "                 'Violation Time', 'Time First Observed', 'Vehicle Year', 'Feet From Curb']\n",
    "nominalFields = list(set(data.columns.values) - set(numericFields) - set(['Issuing Agency']))\n",
    "# Create LabelEncoder() class instance, and then use fit_transform() function to conver nominal to numeric.\n",
    "lb_encoder = LabelEncoder()\n",
    "for label in nominalFields:\n",
    "    data[label] = lb_encoder.fit_transform(data[label])\n",
    "\n",
    "# After convertion, numericFields should be extended\n",
    "numericFields.extend(nominalFields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Scale the data to the range of [0,1] by using scaledData = (value - minimum) / maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minVal = np.min(data[numericFields])\n",
    "maxVal = np.max(data[numericFields])\n",
    "data[numericFields] = (data[numericFields] - minVal) / maxVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4-1**: Generate first dataset, which is only preprocessed by over-sampling approach. The method is to use SMOTE library to over sample the minority classes. Since SMOTE library is unable to deal with NaN value, I replace NaN as -1 before using SMOTE's over sampling. After over-sampling process, the totals of each class are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T         1736\n",
       "S         1736\n",
       "X         1736\n",
       "Others    1736\n",
       "V         1736\n",
       "P         1736\n",
       "Name: Issuing Agency, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(-1)\n",
    "sm = SMOTE(ratio='all',kind='regular', k_neighbors=10, random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X=data[data.columns[:-1]].values, y=data['Issuing Agency'])\n",
    "data = pd.DataFrame(X_res, columns=data.columns[:-1])\n",
    "# data = data.replace(-1,np.nan)\n",
    "data['Issuing Agency'] = y_res\n",
    "data['Issuing Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4-2**: Generate second dataset, which is processed by stratified under-sampling approach and then over-sampling approach. For the under sampling, since class 'P' and 'T' are majority classes, I under sample the class 'T' with 80% and the class 'P' with 70%. After this step, the total of class 'T' is 1215, and the total of class 'P' is 1282. Then for over sampling, I use the same approach as the the step 4-1. The totals of each class are shown below.  \n",
    "\n",
    "For the combination of over sampling and under sampling, I generate two different datasets: one fills the NaN with -1, and another one remains the NaN. The dataset containing NaN values is used to test the robustness of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T         1282\n",
       "V         1282\n",
       "S         1282\n",
       "X         1282\n",
       "P         1282\n",
       "Others    1282\n",
       "Name: Issuing Agency, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified under sampling\n",
    "tmp = data[data['Issuing Agency']=='P'].sample(frac=.8)\n",
    "data = data[data['Issuing Agency']!='P']\n",
    "data = data.append(tmp, ignore_index=True)\n",
    "tmp = data[data['Issuing Agency']=='T'].sample(frac=.7)\n",
    "data = data[data['Issuing Agency']!='T']\n",
    "data = data.append(tmp, ignore_index=True)\n",
    "\n",
    "# Over sampling by using SMOTE\n",
    "data = data.fillna(-1)\n",
    "sm = SMOTE(ratio='all',kind='regular',k_neighbors=10, random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X=data[data.columns[:-1]].values, y=data['Issuing Agency'])\n",
    "data = pd.DataFrame(X_res, columns=data.columns[:-1])\n",
    "#Replace NaN with -1 or not\n",
    "data = data.replace(-1,np.nan)\n",
    "data['Issuing Agency'] = y_res\n",
    "data['Issuing Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: Use classification algorithms from the following six families in order to build models against you balanced data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two dataset, dataset-1 is the result of Step 4-1, which uses SMOTE only, and dataset-2 is the result of Step 4-2, which uses under sample and over sample both.  \n",
    "\n",
    "The table below uses the dataset-1, and Percentage split with 70% for test options. The configurations of each algorithms are:\n",
    "* **Naive Bayes**: set useKernelEstimator = True, rest keep default settings;\n",
    "* **J48**: keep default settings;\n",
    "* **AdaBoost**: classifier = J48, rest keep default settings;\n",
    "* **IBk**: CrossValide = True, meanSquared = True, rest keep default settings;\n",
    "* **MultilayerPerceptron**: hidderLayers = t, learningRate = 0.1, nominalToBinaryFilter = False, normalizeAttributes = False, normalizeNumericClass = False, trainingTime = 1000, rest keep default settings;\n",
    "* **PART**: keep default settings;\n",
    "\n",
    "**<center>Classification results for dataset-1</center>**   \n",
    "\n",
    "|Algorithm Name|Correctly Classified Instances <br/> (Total 3125)|Mean Square Error|True Positive Rate|False Positive Rate|Precision|Recall|F-measure|Time taken to build model|Time taken to test model|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Naive Bayes|3018 (96.576%)|0.0952|0.966|0.007|0.968|0.966|0.966|0.14 s|7.33 s|\n",
    "|J48|3099 (99.168%)|0.0514|0.992|0.002|0.992|0.992|0.992|0.23 s|0 s|\n",
    "|AdaBoost|3112 (99.584%)|0.0371|0.996|0.001|0.996|0.996|0.996|3.39 s|0.03 s|\n",
    "|IBk|3010 (96.32%)|0.1107|0.963|0.007|0.965|0.963|0.963|0 s|4.85 s|\n",
    "|MultilayerPerceptron|3080 (98.56%)|0.0657|0.986|0.003|0.986|0.986|0.986|119.3 s|0.03|\n",
    "|PART|3096 (99.072%)|0.055|0.991|0.002|0.991|0.991|0.991|0.76 s|0.01 s|\n",
    "\n",
    "<br>\n",
    "\n",
    "**<center>Classification results for dataset-2</center>**   \n",
    "\n",
    "|Algorithm Name|Correctly Classified Instances <br/> (Total 2308)|Mean Square Error|True Positive Rate|False Positive Rate|Precision|Recall|F-measure|Time taken to build model|Time taken to test model|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Naive Bayes|2231 (96.6638%)|0.0933|0.967|0.007|0.968|0.967|0.967|0.12|4.36|\n",
    "|J48|2289 (99.1768%)|0.052|0.992|0.002|0.992|0.992|0.992|0.2|0 s|\n",
    "|AdaBoost|2297 (99.5234%)|0.0387|0.995|0.001|0.995|0.995|0.995|2.38 s|0.02 s|\n",
    "|IBk|2209 (95.7106%)|0.1195|0.957|0.009|0.958|0.957|0.956|0 s|2.64 s|\n",
    "|MultilayerPerceptron|2259 (97.8769%)|0.078|0.979|0.004|0.979|0.979|0.979|88.01|0.02|\n",
    "|PART|2277 (98.6568%)|0.0663|0.987|0.003|0.987|0.987|0.987|0.29|0 s|\n",
    "\n",
    "<br>\n",
    "\n",
    "**<center>Classification results for dataset-2 with NaN</center>**   \n",
    "\n",
    "|Algorithm Name|Correctly Classified Instances <br/> (Total 2308)|Mean Square Error|True Positive Rate|False Positive Rate|Precision|Recall|F-measure|Time taken to build model|Time taken to test model|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Naive Bayes|2166 (93.8475%)|0.1243|0.938|0.012|0.944|0.938|0.939|0.11|3.83|\n",
    "|J48|2286 (99.0468%)|0.0544|0.990|0.002|0.991|0.990|0.990|0.2|0 s|\n",
    "|AdaBoost|2301 (99.6967%)|0.0316|0.997|0.001|0.997|0.997|0.997|2.61 s|0.03 s|\n",
    "|IBk|1373 (59.4887%)|0.3673|0.595|0.082|0.614|0.595|0.596|0 s|4.59 s|\n",
    "|MultilayerPerceptron|2254 (97.6603%)|0.0824|0.977|0.005|0.977|0.977|0.977|86.25|0.02|\n",
    "|PART|2277 (98.6135%)|0.0666|0.986|0.003|0.986|0.986|0.986|0.57|0.01 s|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: Provide a ranking of the algorithms, and motivate your answers by referring to the results as obtained in Question 2. Further, you should refer back to the characteristics of these algorithms as discussed in class and in the text book, and list the advatages and disadvantages. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Ranking**  \n",
    "I design a set of criterias to evaluate classification algorithms used above. According to each criteria, I will rank the algorithms based on the results of Q2 and give sores to each of them, and finally rank algorithms by adding all scores they get. The information of criterias can be seen below, a algorithm will get corresponding score at differrent ranks, for example, for accuracy criteria, the algorithm will get 6 scores if it is ranked at 1 place.\n",
    "\n",
    "There are two dataset that I used in Q2, one is using SMOTE approach only, and the other one is using SMOTE and under-sampling approach both, but the results of them are similar, so I use the result of dataset-2 for Q3.  \n",
    "\n",
    "**<center>Ranking criterias and scores</center>**\n",
    "\n",
    "|Criterias|Rank 1|Rank 2|Rank 3|Rank 4|Rank 5|Rank 6|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Accuracy|6|5|4|3|2|1|\n",
    "|ROC|6|5|4|3|2|1|\n",
    "|Speed|6|5|4|3|2|1|\n",
    "|Robustness|6|5|4|3|2|1|\n",
    "\n",
    "**(1) Accuracy**  \n",
    "For accuracy ranking, the rank of algorithms are:  \n",
    "\n",
    "|Algorithms|Accuracy|Rank|Total scores|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|AdaBoost|99.5234%|1|6|\n",
    "|J48|99.1768%|2|5|\n",
    "|PART|98.6568%|3|4|\n",
    "|MultilayerPerceptron|97.8769%|4|3|\n",
    "|Naive Bayes|96.6638%|5|2|\n",
    "|IBk|95.7106%|6|1|\n",
    "\n",
    "\n",
    "**(2) ROC**  \n",
    "For ROC ranking, the rank of algorithms are:  \n",
    "\n",
    "|Algorithms|ROC Area|Rank|Total scores|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|AdaBoost|1.000|1|12|\n",
    "|Naive Bayes|0.999|2|7|\n",
    "|J48|0.997|3|9|\n",
    "|PART|0.997|3|8|\n",
    "|MultilayerPerceptron|0.995|4|6|\n",
    "|IBk|0.965|5|3|\n",
    "\n",
    "\n",
    "**(3) Speed**  \n",
    "For Speed ranking, it includes training time and test time. The rank of algorithms are:  \n",
    "\n",
    "|Algorithms|Training Time|Test Time|Rank|Total scores|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|J48|0.2 s|0 s|1|15|\n",
    "|PART|0.29 s|0 s|2|13|\n",
    "|AdaBoost|2.38 s|0.02 s|3|16|\n",
    "|IBk|0 s|2.46 s|4|6|\n",
    "|Naive Bayes|0.12 s|4.36 s|5|9|\n",
    "|MultilayerPerceptron|88.01 s|0.02 s|6|7|\n",
    "\n",
    "\n",
    "**(4) Robustness**  \n",
    "For Robustness ranking, I test the algorithms with two datasets: one contains NaN and another replace NaN as -1, the rank of algorithms are:  \n",
    "\n",
    "|Algorithms|Accuracy with NaN|Accuracy without NaN|Differences|Rank|Total scores|\n",
    "|:---|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|PART|98.6135%|98.6568%|0.0433|1|19|\n",
    "|J48|99.0468%|99.1768%|0.13|2|20|\n",
    "|AdaBoost|99.6967%|99.5234%|0.17|3|20|\n",
    "|MultilayerPerceptron|97.6603%|97.8769%|0.2166|4|10|\n",
    "|Naive Bayes|93.8475%|96.6638%|2.8163|5|12|\n",
    "|IBk|59.4887%|95.7106%|36.2219|6|7|  \n",
    "\n",
    "The final rank of algorithms are:   \n",
    "\n",
    "|Algorithms|Rank|Total scores|\n",
    "|:---|:-:|:-:|\n",
    "|AdaBoost|1|20|\n",
    "|J48|2|20|\n",
    "|PART|3|19|\n",
    "|Naive Bayes|4|12|\n",
    "|MultilayerPerceptron|5|10|\n",
    "|IBk|6|7| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Advatages and Disadvantages**  \n",
    "**3.2.1 Decision Tree**  \n",
    "(1) Advantages:\n",
    "* Comparable classification accuracy with other methods. According to the accuracy criterion in the section 3.1, J48's accuracy is up to 99.1768%, which is comparable high and ranked at 2nd place. For the second criterion ROC Area, J48 also performances well with 0.997 ROC area.\n",
    "* Relatively faster learning speed. The dataset I used has 7692 records, and 70% of dataset is used for training and 30% is for testing. The J48 only costs 0.2 seconds to generate the model and almost 0 seconds for testing, which is ranked at 1st place among the algorithms. \n",
    "* Simple and easy to understand. \n",
    "\n",
    "(2) Disadvantages:\n",
    "* It is easy to be overffiting. \n",
    "* Split criterion. Split functions greatly effect accuracy of decision tree.\n",
    "* Slightly sensitive to missing values. From the result of robutness testing, the accuracy is lower when the dataset contains NaN values.\n",
    "\n",
    "**3.2.2 Bayesian learner**   \n",
    "(1) Advantages:\n",
    "* Easy to implement. \n",
    "* According to the criterion ROC Area, Bayesian learner has a better performance comparing with Decision tree, lazy learner, artificial neural network and rule learner. \n",
    "\n",
    "(2) Disadvantages:\n",
    "* Sensitive to zero data. Naïve Bayesian prediction requires each conditional probability be non-zero. Otherwise, the predicted probability will be zero.\n",
    "* Class conditional independence effects the accuracy. It assumes that the effect of an attribute value on a given class is independent of the values of the other attributes.\n",
    "\n",
    "**3.2.3 Artificial neural network**   \n",
    "(1) Advantages:\n",
    "* High tolerance to noisy data.\n",
    "* Ability to classify untrained patterns.\n",
    "* Well-suited for continuous-valued inputs and outputs.\n",
    "* Successful on an array of real-world data.\n",
    "* Algorithms are inherently parallel.\n",
    "* Techniques have recently been developed for the extraction of rules from trained neural networks.\n",
    "\n",
    "(2) Disadvantages:\n",
    "* Long training time. According to the speed criterion in the 3.1, MultilayerPerceptron costs 88.01 seconds to train a model, which is far more longer than other algorithms.\n",
    "* Lots of parameters typically best determined empirically.\n",
    "* Can only handle numeric data. Users have to convert nominal data to numeric data.\n",
    "* Poor interpretability: Difficult to interpret the symbolic meaning behind the learned weights and of “hidden units” in the network.\n",
    "\n",
    "**3.2.4 Meta-learner**   \n",
    "(1) Advantages:\n",
    "* Comparable classification accuracy with other methods. According to the accuracy and ROC area criteria, Adaboost performances best.\n",
    "* Comparable fast training speed. It costs 2.38 seconds to train the model, although it is slower than J48 and PART, it far more faster than Artificial neural network.\n",
    "\n",
    "(2) Disadvantages:\n",
    "* It is easy to be overfitting as it focuses on the misclassified tuples.\n",
    "* It doesn't work online learning.\n",
    "* Slightly sensitive to missing values. From the result of robutness testing, the accuracy is changed when the dataset contains NaN values.\n",
    "\n",
    "**3.2.5 Lazy learner**   \n",
    "(1) Advantages:\n",
    "* Less time in training. According to the speed test, IBk costs 0 second to finish training process.\n",
    "* Easy to implement.   \n",
    "\n",
    "(2) Disadvantages:\n",
    "* Need more time in testing or classification. \n",
    "* Require efficient storage techniques and high computational ability\n",
    "* Sensitive to missing values. The accuracy is pretty low when the dataset contains NaN values.\n",
    "\n",
    "**3.2.6 Rule learner**   \n",
    "(1) Advantages:\n",
    "* Relatively faster learning speed and testing or classification speed. \n",
    "* It is not sensitive to missing value. \n",
    "* Rules are easier to understand than large trees.\n",
    "\n",
    "(2) Disadvantages:\n",
    "* Rules are easy to be overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
